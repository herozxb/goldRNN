{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import quandl\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=quandl.get(\"LBMA/GOLD\", authtoken=\"ZbxGsy8jS4AxssbNsHEp\", start_date=\"2009-01-01\")\n",
    "csvfile = file('data.csv', 'wb')\n",
    "writer = csv.writer(csvfile)\n",
    "writer.writerow(['date', 'price'])\n",
    "i=1\n",
    "data_input = [('0','0')]\n",
    "for data_ in data[\"USD (AM)\"]:\n",
    "    temp_data = (str(i),str(data_))\n",
    "    data_input.append(temp_data)\n",
    "    i = i+1\n",
    "\n",
    "writer.writerows(data_input)\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1896.5\n"
     ]
    }
   ],
   "source": [
    "temp =data[\"USD (AM)\"][0]\n",
    "maxResult = 0\n",
    "for data_ in data[\"USD (AM)\"]:\n",
    "    result = data_ \n",
    "    if result >= maxResult:\n",
    "        maxResult = result\n",
    "    \n",
    "print maxResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas, matplotlib.pyplot as plt, numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        a = dataset[i:(i + look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1923, 102)\n",
      "Epoch 1/100\n",
      "10s - loss: 0.0220\n",
      "Epoch 2/100\n",
      "9s - loss: 1.0757e-04\n",
      "Epoch 3/100\n",
      "9s - loss: 1.1316e-04\n",
      "Epoch 4/100\n",
      "9s - loss: 1.1411e-04\n",
      "Epoch 5/100\n",
      "9s - loss: 1.1752e-04\n",
      "Epoch 6/100\n",
      "9s - loss: 1.0718e-04\n",
      "Epoch 7/100\n",
      "9s - loss: 1.0866e-04\n",
      "Epoch 8/100\n",
      "9s - loss: 1.0599e-04\n",
      "Epoch 9/100\n",
      "9s - loss: 1.0408e-04\n",
      "Epoch 10/100\n",
      "9s - loss: 1.0226e-04\n",
      "Epoch 11/100\n",
      "10s - loss: 1.0392e-04\n",
      "Epoch 12/100\n",
      "9s - loss: 9.7391e-05\n",
      "Epoch 13/100\n",
      "9s - loss: 9.9450e-05\n",
      "Epoch 14/100\n",
      "9s - loss: 9.6854e-05\n",
      "Epoch 15/100\n",
      "8s - loss: 9.8405e-05\n",
      "Epoch 16/100\n",
      "8s - loss: 1.0037e-04\n",
      "Epoch 17/100\n",
      "9s - loss: 9.5018e-05\n",
      "Epoch 18/100\n",
      "8s - loss: 9.5697e-05\n",
      "Epoch 19/100\n",
      "8s - loss: 9.9289e-05\n",
      "Epoch 20/100\n",
      "9s - loss: 9.3499e-05\n",
      "Epoch 21/100\n",
      "9s - loss: 9.6897e-05\n",
      "Epoch 22/100\n",
      "9s - loss: 9.6702e-05\n",
      "Epoch 23/100\n",
      "9s - loss: 9.7096e-05\n",
      "Epoch 24/100\n",
      "9s - loss: 9.2861e-05\n",
      "Epoch 25/100\n",
      "8s - loss: 9.5638e-05\n",
      "Epoch 26/100\n",
      "8s - loss: 9.6843e-05\n",
      "Epoch 27/100\n",
      "8s - loss: 9.0138e-05\n",
      "Epoch 28/100\n",
      "9s - loss: 9.0550e-05\n",
      "Epoch 29/100\n",
      "9s - loss: 9.8928e-05\n",
      "Epoch 30/100\n",
      "8s - loss: 8.9253e-05\n",
      "Epoch 31/100\n",
      "8s - loss: 9.5524e-05\n",
      "Epoch 32/100\n",
      "9s - loss: 9.4128e-05\n",
      "Epoch 33/100\n",
      "8s - loss: 9.4953e-05\n",
      "Epoch 34/100\n",
      "8s - loss: 9.4473e-05\n",
      "Epoch 35/100\n",
      "8s - loss: 9.1716e-05\n",
      "Epoch 36/100\n",
      "8s - loss: 9.1617e-05\n",
      "Epoch 37/100\n",
      "8s - loss: 9.2992e-05\n",
      "Epoch 38/100\n",
      "8s - loss: 9.2414e-05\n",
      "Epoch 39/100\n",
      "8s - loss: 9.5174e-05\n",
      "Epoch 40/100\n",
      "9s - loss: 9.3124e-05\n",
      "Epoch 41/100\n",
      "8s - loss: 9.0676e-05\n",
      "Epoch 42/100\n",
      "8s - loss: 9.4333e-05\n",
      "Epoch 43/100\n",
      "8s - loss: 9.0813e-05\n",
      "Epoch 44/100\n",
      "8s - loss: 9.3486e-05\n",
      "Epoch 45/100\n",
      "8s - loss: 9.3496e-05\n",
      "Epoch 46/100\n",
      "8s - loss: 8.8997e-05\n",
      "Epoch 47/100\n",
      "8s - loss: 9.1172e-05\n",
      "Epoch 48/100\n",
      "9s - loss: 9.1893e-05\n",
      "Epoch 49/100\n",
      "9s - loss: 9.3166e-05\n",
      "Epoch 50/100\n",
      "8s - loss: 9.3527e-05\n",
      "Epoch 51/100\n",
      "9s - loss: 8.6567e-05\n",
      "Epoch 52/100\n",
      "9s - loss: 9.2200e-05\n",
      "Epoch 53/100\n",
      "8s - loss: 8.7973e-05\n",
      "Epoch 54/100\n",
      "8s - loss: 8.6769e-05\n",
      "Epoch 55/100\n",
      "8s - loss: 9.1199e-05\n",
      "Epoch 56/100\n",
      "8s - loss: 9.3473e-05\n",
      "Epoch 57/100\n",
      "9s - loss: 9.1344e-05\n",
      "Epoch 58/100\n",
      "8s - loss: 9.3030e-05\n",
      "Epoch 59/100\n",
      "9s - loss: 8.8241e-05\n",
      "Epoch 60/100\n",
      "9s - loss: 8.7719e-05\n",
      "Epoch 61/100\n",
      "9s - loss: 8.9416e-05\n",
      "Epoch 62/100\n",
      "9s - loss: 9.0413e-05\n",
      "Epoch 63/100\n",
      "9s - loss: 9.2254e-05\n",
      "Epoch 64/100\n",
      "9s - loss: 8.8263e-05\n",
      "Epoch 65/100\n",
      "8s - loss: 9.0526e-05\n",
      "Epoch 66/100\n",
      "8s - loss: 8.7588e-05\n",
      "Epoch 67/100\n",
      "8s - loss: 8.5117e-05\n",
      "Epoch 68/100\n",
      "9s - loss: 8.9065e-05\n",
      "Epoch 69/100\n",
      "8s - loss: 9.3730e-05\n",
      "Epoch 70/100\n",
      "9s - loss: 8.5279e-05\n",
      "Epoch 71/100\n",
      "8s - loss: 8.8756e-05\n",
      "Epoch 72/100\n",
      "8s - loss: 9.1394e-05\n",
      "Epoch 73/100\n",
      "9s - loss: 9.5229e-05\n",
      "Epoch 74/100\n",
      "8s - loss: 9.3181e-05\n",
      "Epoch 75/100\n",
      "8s - loss: 8.6818e-05\n",
      "Epoch 76/100\n",
      "8s - loss: 9.2373e-05\n",
      "Epoch 77/100\n",
      "8s - loss: 8.9158e-05\n",
      "Epoch 78/100\n",
      "8s - loss: 9.1454e-05\n",
      "Epoch 79/100\n",
      "8s - loss: 9.0897e-05\n",
      "Epoch 80/100\n",
      "8s - loss: 8.7514e-05\n",
      "Epoch 81/100\n",
      "8s - loss: 9.1427e-05\n",
      "Epoch 82/100\n",
      "9s - loss: 8.5125e-05\n",
      "Epoch 83/100\n",
      "8s - loss: 8.8401e-05\n",
      "Epoch 84/100\n",
      "8s - loss: 9.4370e-05\n",
      "Epoch 85/100\n",
      "8s - loss: 8.6516e-05\n",
      "Epoch 86/100\n",
      "8s - loss: 8.5589e-05\n",
      "Epoch 87/100\n",
      "8s - loss: 8.6517e-05\n",
      "Epoch 88/100\n",
      "8s - loss: 8.6600e-05\n",
      "Epoch 89/100\n",
      "8s - loss: 9.1284e-05\n",
      "Epoch 90/100\n",
      "8s - loss: 8.4731e-05\n",
      "Epoch 91/100\n",
      "8s - loss: 8.8149e-05\n",
      "Epoch 92/100\n",
      "8s - loss: 8.8952e-05\n",
      "Epoch 93/100\n",
      "8s - loss: 8.8249e-05\n",
      "Epoch 94/100\n",
      "8s - loss: 8.9036e-05\n",
      "Epoch 95/100\n",
      "8s - loss: 8.7199e-05\n",
      "Epoch 96/100\n",
      "8s - loss: 8.6452e-05\n",
      "Epoch 97/100\n",
      "8s - loss: 8.7944e-05\n",
      "Epoch 98/100\n",
      "8s - loss: 9.2174e-05\n",
      "Epoch 99/100\n",
      "9s - loss: 8.5317e-05\n",
      "Epoch 100/100\n",
      "8s - loss: 8.7929e-05\n",
      "('Train Score: ', array([[ 0.13360771]]))\n",
      "('Test Score: ', array([[ 0.07527803]]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataframe = pandas.read_csv('data.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "\n",
    "#scale\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.95)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 5\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(6, input_dim=look_back))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, nb_epoch=100, batch_size=1, verbose=2)\n",
    "\n",
    "\n",
    "# Estimate model performance\n",
    "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
    "print('Train Score: ', scaler.inverse_transform(numpy.array([[trainScore]])))\n",
    "testScore = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test Score: ', scaler.inverse_transform(numpy.array([[testScore]])))\n",
    "\n",
    "# generate predictions for training\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71058971]\n",
      " [ 0.71191937]\n",
      " [ 0.71227783]\n",
      " [ 0.70691961]\n",
      " [ 0.70750147]\n",
      " [ 0.70729357]\n",
      " [ 0.70168209]\n",
      " [ 0.70065534]\n",
      " [ 0.6980083 ]\n",
      " [ 0.69542652]\n",
      " [ 0.69129372]\n",
      " [ 0.69278461]\n",
      " [ 0.70032984]\n",
      " [ 0.70267141]\n",
      " [ 0.71091092]\n",
      " [ 0.71262723]\n",
      " [ 0.70754242]\n",
      " [ 0.70305544]\n",
      " [ 0.70249993]\n",
      " [ 0.70017952]\n",
      " [ 0.69831371]\n",
      " [ 0.69553006]\n",
      " [ 0.69520712]\n",
      " [ 0.69537163]\n",
      " [ 0.6971308 ]\n",
      " [ 0.70297253]\n",
      " [ 0.70571953]\n",
      " [ 0.70639247]\n",
      " [ 0.70640343]\n",
      " [ 0.70170987]\n",
      " [ 0.69893456]\n",
      " [ 0.70142537]\n",
      " [ 0.69807321]\n",
      " [ 0.69319695]\n",
      " [ 0.67733395]\n",
      " [ 0.67001235]\n",
      " [ 0.66443467]\n",
      " [ 0.66602665]\n",
      " [ 0.66431785]\n",
      " [ 0.66342705]\n",
      " [ 0.66444826]\n",
      " [ 0.66376019]\n",
      " [ 0.66216218]\n",
      " [ 0.66563696]\n",
      " [ 0.6698463 ]\n",
      " [ 0.67042702]\n",
      " [ 0.66837567]\n",
      " [ 0.66922241]\n",
      " [ 0.67039734]\n",
      " [ 0.67251688]\n",
      " [ 0.67110527]\n",
      " [ 0.66927826]\n",
      " [ 0.67247069]\n",
      " [ 0.67746103]\n",
      " [ 0.68330228]\n",
      " [ 0.6834299 ]\n",
      " [ 0.68702525]\n",
      " [ 0.68167788]\n",
      " [ 0.67902243]\n",
      " [ 0.68741822]\n",
      " [ 0.67919153]\n",
      " [ 0.66635096]\n",
      " [ 0.64986062]\n",
      " [ 0.64871979]\n",
      " [ 0.64763016]\n",
      " [ 0.64973402]\n",
      " [ 0.63964772]\n",
      " [ 0.64088881]\n",
      " [ 0.6427691 ]\n",
      " [ 0.64077759]\n",
      " [ 0.62969339]\n",
      " [ 0.62727302]\n",
      " [ 0.62770951]\n",
      " [ 0.62667   ]\n",
      " [ 0.62677765]\n",
      " [ 0.61888337]\n",
      " [ 0.61832356]\n",
      " [ 0.61561728]\n",
      " [ 0.61730283]\n",
      " [ 0.6180982 ]\n",
      " [ 0.61947644]\n",
      " [ 0.61750805]\n",
      " [ 0.61077964]\n",
      " [ 0.61071467]\n",
      " [ 0.61226702]\n",
      " [ 0.60025477]\n",
      " [ 0.59889019]\n",
      " [ 0.60013819]\n",
      " [ 0.59769845]\n",
      " [ 0.59832358]\n",
      " [ 0.59684479]\n",
      " [ 0.59655952]\n",
      " [ 0.60036337]\n",
      " [ 0.60404158]\n",
      " [ 0.60998726]\n",
      " [ 0.60694778]]\n",
      "(96, 1)\n"
     ]
    }
   ],
   "source": [
    "print testPredict\n",
    "print testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1151.07646477"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.60694778*1896.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.70896393  0.70482469  0.7061429   0.71136308  0.70801479]]\n",
      "\n",
      " [[ 0.70482469  0.7061429   0.71136308  0.70801479  0.71030849]]\n",
      "\n",
      " [[ 0.7061429   0.71136308  0.70801479  0.71030849  0.71017665]]\n",
      "\n",
      " [[ 0.71136308  0.70801479  0.71030849  0.71017665  0.70355928]]\n",
      "\n",
      " [[ 0.70801479  0.71030849  0.71017665  0.70355928  0.70577383]]\n",
      "\n",
      " [[ 0.71030849  0.71017665  0.70355928  0.70577383  0.70514113]]\n",
      "\n",
      " [[ 0.71017665  0.70355928  0.70577383  0.70514113  0.6983918 ]]\n",
      "\n",
      " [[ 0.70355928  0.70577383  0.70514113  0.6983918   0.69860274]]\n",
      "\n",
      " [[ 0.70577383  0.70514113  0.6983918   0.69860274  0.69541264]]\n",
      "\n",
      " [[ 0.70514113  0.6983918   0.69860274  0.69541264  0.69309253]]\n",
      "\n",
      " [[ 0.6983918   0.69860274  0.69541264  0.69309253  0.68847877]]\n",
      "\n",
      " [[ 0.69860274  0.69541264  0.69309253  0.68847877  0.69153708]]\n",
      "\n",
      " [[ 0.69541264  0.69309253  0.68847877  0.69153708  0.70039552]]\n",
      "\n",
      " [[ 0.69309253  0.68847877  0.69153708  0.70039552  0.70131826]]\n",
      "\n",
      " [[ 0.68847877  0.69153708  0.70039552  0.70131826  0.71117854]]\n",
      "\n",
      " [[ 0.69153708  0.70039552  0.70131826  0.71117854  0.71078306]]\n",
      "\n",
      " [[ 0.70039552  0.70131826  0.71117854  0.71078306  0.70427108]]\n",
      "\n",
      " [[ 0.70131826  0.71117854  0.71078306  0.70427108  0.69997364]]\n",
      "\n",
      " [[ 0.71117854  0.71078306  0.70427108  0.69997364  0.70050097]]\n",
      "\n",
      " [[ 0.71078306  0.70427108  0.69997364  0.70050097  0.69770628]]\n",
      "\n",
      " [[ 0.70427108  0.69997364  0.70050097  0.69770628  0.69607174]]\n",
      "\n",
      " [[ 0.69997364  0.70050097  0.69770628  0.69607174  0.69298714]]\n",
      "\n",
      " [[ 0.70050097  0.69770628  0.69607174  0.69298714  0.69340897]]\n",
      "\n",
      " [[ 0.69770628  0.69607174  0.69298714  0.69340897  0.6935935 ]]\n",
      "\n",
      " [[ 0.69607174  0.69298714  0.69340897  0.6935935   0.69580811]]\n",
      "\n",
      " [[ 0.69298714  0.69340897  0.6935935   0.69580811  0.70258373]]\n",
      "\n",
      " [[ 0.69340897  0.6935935   0.69580811  0.70258373  0.70440292]]\n",
      "\n",
      " [[ 0.6935935   0.69580811  0.70258373  0.70440292  0.7046138 ]]\n",
      "\n",
      " [[ 0.69580811  0.70258373  0.70440292  0.7046138   0.70437652]]\n",
      "\n",
      " [[ 0.70258373  0.70440292  0.7046138   0.70437652  0.69855005]]\n",
      "\n",
      " [[ 0.70440292  0.7046138   0.70437652  0.69855005  0.69646722]]\n",
      "\n",
      " [[ 0.7046138   0.70437652  0.69855005  0.69646722  0.70018458]]\n",
      "\n",
      " [[ 0.70437652  0.69855005  0.69646722  0.70018458  0.6953072 ]]\n",
      "\n",
      " [[ 0.69855005  0.69646722  0.70018458  0.6953072   0.69029796]]\n",
      "\n",
      " [[ 0.69646722  0.70018458  0.6953072   0.69029796  0.67176384]]\n",
      "\n",
      " [[ 0.70018458  0.6953072   0.69029796  0.67176384  0.66728187]]\n",
      "\n",
      " [[ 0.6953072   0.69029796  0.67176384  0.66728187  0.66174537]]\n",
      "\n",
      " [[ 0.69029796  0.67176384  0.66728187  0.66174537  0.66548908]]\n",
      "\n",
      " [[ 0.67176384  0.66728187  0.66174537  0.66548908  0.66248357]]\n",
      "\n",
      " [[ 0.66728187  0.66174537  0.66548908  0.66248357  0.66211444]]\n",
      "\n",
      " [[ 0.66174537  0.66548908  0.66248357  0.66211444  0.66332722]]\n",
      "\n",
      " [[ 0.66548908  0.66248357  0.66211444  0.66332722  0.66235173]]\n",
      "\n",
      " [[ 0.66248357  0.66211444  0.66332722  0.66235173  0.66053259]]\n",
      "\n",
      " [[ 0.66211444  0.66332722  0.66235173  0.66053259  0.66525185]]\n",
      "\n",
      " [[ 0.66332722  0.66235173  0.66053259  0.66525185  0.66952282]]\n",
      "\n",
      " [[ 0.66235173  0.66053259  0.66525185  0.66952282  0.66923279]]\n",
      "\n",
      " [[ 0.66053259  0.66525185  0.66952282  0.66923279  0.66646457]]\n",
      "\n",
      " [[ 0.66525185  0.66952282  0.66923279  0.66646457  0.66807282]]\n",
      "\n",
      " [[ 0.66952282  0.66923279  0.66646457  0.66807282  0.6692856 ]]\n",
      "\n",
      " [[ 0.66923279  0.66646457  0.66807282  0.6692856   0.67171109]]\n",
      "\n",
      " [[ 0.66646457  0.66807282  0.6692856   0.67171109  0.6692856 ]]\n",
      "\n",
      " [[ 0.66807282  0.6692856   0.67171109  0.6692856   0.66749281]]\n",
      "\n",
      " [[ 0.6692856   0.67171109  0.6692856   0.66749281  0.67186922]]\n",
      "\n",
      " [[ 0.67171109  0.6692856   0.66749281  0.67186922  0.67724758]]\n",
      "\n",
      " [[ 0.6692856   0.66749281  0.67186922  0.67724758  0.683285  ]]\n",
      "\n",
      " [[ 0.66749281  0.67186922  0.67724758  0.683285    0.68178225]]\n",
      "\n",
      " [[ 0.67186922  0.67724758  0.683285    0.68178225  0.68636966]]\n",
      "\n",
      " [[ 0.67724758  0.683285    0.68178225  0.68636966  0.67851311]]\n",
      "\n",
      " [[ 0.683285    0.68178225  0.68636966  0.67851311  0.6770367 ]]\n",
      "\n",
      " [[ 0.68178225  0.68636966  0.67851311  0.6770367   0.68787247]]\n",
      "\n",
      " [[ 0.68636966  0.67851311  0.6770367   0.68787247  0.6754021 ]]\n",
      "\n",
      " [[ 0.67851311  0.6770367   0.68787247  0.6754021   0.6620881 ]]\n",
      "\n",
      " [[ 0.6770367   0.68787247  0.6754021   0.6620881   0.64466125]]\n",
      "\n",
      " [[ 0.68787247  0.6754021   0.6620881   0.64466125  0.64798319]]\n",
      "\n",
      " [[ 0.6754021   0.6620881   0.64466125  0.64798319  0.64629579]]\n",
      "\n",
      " [[ 0.6620881   0.64466125  0.64798319  0.64629579  0.64961773]]\n",
      "\n",
      " [[ 0.64466125  0.64798319  0.64629579  0.64961773  0.635961  ]]\n",
      "\n",
      " [[ 0.64798319  0.64629579  0.64961773  0.635961    0.6406275 ]]\n",
      "\n",
      " [[ 0.64629579  0.64961773  0.635961    0.6406275   0.64199847]]\n",
      "\n",
      " [[ 0.64961773  0.635961    0.6406275   0.64199847  0.63973111]]\n",
      "\n",
      " [[ 0.635961    0.6406275   0.64199847  0.63973111  0.62602162]]\n",
      "\n",
      " [[ 0.6406275   0.64199847  0.63973111  0.62602162  0.62615347]]\n",
      "\n",
      " [[ 0.64199847  0.63973111  0.62602162  0.62615347  0.62699711]]\n",
      "\n",
      " [[ 0.63973111  0.62602162  0.62615347  0.62699711  0.62604803]]\n",
      "\n",
      " [[ 0.62602162  0.62615347  0.62699711  0.62604803  0.62610078]]\n",
      "\n",
      " [[ 0.62615347  0.62699711  0.62604803  0.62610078  0.61626685]]\n",
      "\n",
      " [[ 0.62699711  0.62604803  0.62610078  0.61626685  0.617796  ]]\n",
      "\n",
      " [[ 0.62604803  0.62610078  0.61626685  0.617796    0.61423677]]\n",
      "\n",
      " [[ 0.62610078  0.61626685  0.617796    0.61423677  0.61753231]]\n",
      "\n",
      " [[ 0.61626685  0.617796    0.61423677  0.61753231  0.61758506]]\n",
      "\n",
      " [[ 0.617796    0.61423677  0.61753231  0.61758506  0.61943054]]\n",
      "\n",
      " [[ 0.61423677  0.61753231  0.61758506  0.61943054  0.61634594]]\n",
      "\n",
      " [[ 0.61753231  0.61758506  0.61943054  0.61634594  0.60870028]]\n",
      "\n",
      " [[ 0.61758506  0.61943054  0.61634594  0.60870028  0.61025578]]\n",
      "\n",
      " [[ 0.61943054  0.61634594  0.60870028  0.61025578  0.61215395]]\n",
      "\n",
      " [[ 0.61634594  0.60870028  0.61025578  0.61215395  0.59712631]]\n",
      "\n",
      " [[ 0.60870028  0.61025578  0.61215395  0.59712631  0.59839177]]\n",
      "\n",
      " [[ 0.61025578  0.61215395  0.59712631  0.59839177  0.59984183]]\n",
      "\n",
      " [[ 0.61215395  0.59712631  0.59839177  0.59984183  0.5972845 ]]\n",
      "\n",
      " [[ 0.59712631  0.59839177  0.59984183  0.5972845   0.59815454]]\n",
      "\n",
      " [[ 0.59839177  0.59984183  0.5972845   0.59815454  0.59612447]]\n",
      "\n",
      " [[ 0.59984183  0.5972845   0.59815454  0.59612447  0.59636176]]\n",
      "\n",
      " [[ 0.5972845   0.59815454  0.59612447  0.59636176  0.60097551]]\n",
      "\n",
      " [[ 0.59815454  0.59612447  0.59636176  0.60097551  0.60469294]]\n",
      "\n",
      " [[ 0.59612447  0.59636176  0.60097551  0.60469294  0.61117852]]\n",
      "\n",
      " [[ 0.59636176  0.60097551  0.60469294  0.61117852  0.60566837]]]\n",
      "(96, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "#1896.5\n",
    "print testX\n",
    "print testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1148.6500637049999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.60566837*1896.5  #2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1159.10006318"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.61117852*1896.5  #2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1146.80016071"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.60469294*1896.5  #2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1139.750054715"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.60097551*1896.5 #2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.614764039019246"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1165.9/1896.5      #2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.618534141840232"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1173.05/1896.5     #2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6211442130239916"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1178/1896.5        #2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6201423675191141"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1176.1/1896.5      #2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6238861059847087"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1183.2/1896.5      #2027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testInputX =[[[ 0.59636176,  0.60097551,  0.60469294 , 0.61117852 , 0.60566837]]]\n",
    "testInputX=numpy.array(testInputX)\n",
    "testInputXPredict = model.predict(testInputX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.60694778]]\n"
     ]
    }
   ],
   "source": [
    "print testInputXPredict #2023\n",
    "#[[ 0.6237635]]         #2028\n",
    "#[[ 0.62435049]]         #2029\n",
    "#[[ 0.62477851]]         #2030\n",
    "#[[ 0.62537682]]         #2031\n",
    "#[[ 0.62587976]]         #2032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1182.96747775"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6237635*1896.5\n",
    "#(0.62435049-0.6237635)/0.62435049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6237635 ]\n",
      " [ 0.62435049]\n",
      " [ 0.62477851]\n",
      " [ 0.62537682]\n",
      " [ 0.62587976]]\n"
     ]
    }
   ],
   "source": [
    "inputX = [[[0.614764039019246 ,0.618534141840232,0.6211442130239916,0.6201423675191141,0.6238861059847087]],\n",
    "         [[0.618534141840232,0.6211442130239916,0.6201423675191141,0.6238861059847087,0.6237635]],\n",
    "         [[0.6211442130239916,0.6201423675191141,0.6238861059847087,0.6237635,0.62435049]],\n",
    "         [[0.6201423675191141,0.6238861059847087,0.6237635,0.62435049,0.62477851]],\n",
    "         [[0.6238861059847087,0.6237635,0.62435049,0.62477851,0.62537682]]]\n",
    "\n",
    "InputX=numpy.array(inputX)\n",
    "InputXPredict = model.predict(InputX)\n",
    "print InputXPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#print(scaler.inverse_transform(testPredict))\n",
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(dataset)\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
